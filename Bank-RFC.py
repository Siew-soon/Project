# -*- coding: utf-8 -*-
"""bank-marketing-campaign-classification-98.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xs5642tSL81jlK9r-xGK_2oJnLz7UE_n

![o](https://www.appletechsoft.com/wp-content/uploads/2021/05/AI-Machine-Learning-are-Transforming-the-Banking-Industry.jpg)

### Problem Definition:

The objective is to analyze the dataset to find insights and develop strategies to improve the effectiveness of future marketing campaigns for a financial institution. Specifically, we aim to identify patterns and factors influencing whether clients subscribe to a term deposit account. By understanding these patterns, the bank can tailor its marketing strategies to target the right audience segments and enhance campaign performance.
<hr/>

**Term** **deposit**
    is a fixed deposit or time deposit, is a type of investment offered by banks and financial institutions. In a term deposit, an individual deposits a certain amount of money with the bank for a fixed period of time, known as the term or maturity period. The money is held by the bank for the specified duration, during which it earns a fixed interest rate.

### Dataset Overview:
The dataset contains information collected during the bank's marketing campaigns. It includes various features related to bank clients, their interactions with the bank, and the outcomes of previous marketing efforts. The target variable indicates whether a client has subscribed to a term deposit account.

### Description of Columns:
1. **Age**: Numeric feature representing the age of the bank client.
2. **Job**: Categorical feature indicating the type of job the client has.
3. **Marital**: Categorical feature indicating the marital status of the client.
4. **Education**: Categorical feature representing the educational level of the client.
5. **Default**: Categorical feature indicating whether the client has credit in default.
6. **Housing**: Categorical feature indicating whether the client has a housing loan.
7. **Loan**: Categorical feature indicating whether the client has a personal loan.
8. **Balance**: Numeric feature representing the balance of the individual.
9. **Contact**: Categorical feature indicating the communication type used to contact the client.
10. **Month**: Categorical feature indicating the month of the last contact.
11. **Day**: Categorical feature indicating the day of the week of the last contact.
12. **Duration**: Numeric feature representing the duration of the last contact in seconds.
13. **Campaign**: Numeric feature representing the number of contacts performed during the current campaign for this client.
14. **Pdays**: Numeric feature representing the number of days since the client was last contacted from a previous campaign.
15. **Previous**: Numeric feature representing the number of contacts performed before the current campaign for this client.
16. **Poutcome**: Categorical feature representing the outcome of the previous marketing campaign.
17. **deposite (Target)**: Binary feature indicating whether the client has subscribed to a term deposit.

### Methodology:

We use model like:
- Random Forest.

Evaluated using metrics like
- accuracy
- precision
- recall
- ROC-AUC.
This data-driven approach enables organizations to tailor strategies for enhanced customer engagement and business growth.

###Hyperparameters Meaning:
1. Model Complexity:

Parameters like **max_depth**, **min_samples_split**, **min_samples_leaf**, **max_leaf_nodes** and **ccp_alpha** help control the complexity of each tree, preventing overfitting.

2. Randomness and Diversity:

Parameters like **n_estimators**, **criterion**, **max_features**, and **bootstrap** introduce randomness and diversity in the model, which improves generalization and robustness.

3. Efficiency:

Parameters like **n_jobs** control the computational efficiency and verbosity during training.

4. Reproducibility:

The **random_state** parameter ensures that results are reproducible.

# Import Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np                                              # Import numpy for numerical operations
import pandas as pd                                             # Import pandas for data manipulation
import seaborn as sns                                           # Import seaborn for statistical data visualization
import matplotlib.pyplot as plt                                 # Import matplotlib for plotting
from sklearn.metrics import ConfusionMatrixDisplay              # Import ConfusionMatrixDisplay for displaying confusion matrices
from sklearn.ensemble import RandomForestClassifier             # Import RandomForestClassifier from sklearn's ensemble module
from sklearn.model_selection import train_test_split            # Import train_test_split to split data into training and testing sets
from sklearn.preprocessing import LabelEncoder, StandardScaler  # Import LabelEncoder and StandardScaler for data preprocessing
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    confusion_matrix, classification_report, roc_curve, auc)    # Import various metrics for evaluating classifier performance
# %matplotlib inline
import warnings                                                 # Import warnings module to handle warnings
warnings.filterwarnings("ignore")                               # Ignore any warnings

"""#### Data Loading and Exploration"""

df=pd.read_csv('/bank.csv')
df.head()

df.tail()

df.shape

df.info()

df.describe()

df.sample(5)

"""#### Missing Values"""

null_counts = df.isnull().sum()
print(null_counts)

"""we see the is no missing values

# Exploratory Data Analysis (EDA)
"""

df.head()

"""Target class weight"""

plt.figure(figsize=(8, 6))
df['deposit'].value_counts().plot(kind='bar', color=['blue', 'green'])
plt.xlabel('Deposit')
plt.ylabel('Count')
plt.title('Bar Plot of Deposit')
plt.xticks(rotation=0)
plt.show()

"""# prepare data for modeling"""

df.head(2)

"""## Separate categorical and numerical columns"""

categorical_columns = df.select_dtypes(include=['object']).columns
numerical_columns = df.select_dtypes(exclude=['object']).columns

df[numerical_columns].head(3)

df[categorical_columns].head(3)

"""## convert categorical columns to numerical

Apply label encoding to categorical columns
"""

label_encoder = LabelEncoder()
for column in categorical_columns:
    df[column] = label_encoder.fit_transform(df[column])

"""Apply scaling to numerical columns"""

scaler = StandardScaler()
df[numerical_columns] = scaler.fit_transform(df[numerical_columns])
df.head(3)

"""# Data spliting

Split features (data) and target variable
"""

X = df.drop(columns=['deposit'])
y = df['deposit']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print('train features shape: ',X_train.shape)
print('train target   shape: ',y_train.shape)
print('__________\n')
print('test  features shape: ',X_test.shape)
print('test  target   shape: ',y_test.shape)

"""# Modeling

## Random forest classifier

### model training
"""

RF = RandomForestClassifier(
    n_estimators=10,  # Increased number of trees for better generalization
    criterion="entropy",  # Using entropy for information gain
    max_depth=10,  # Limiting the maximum depth to avoid overfitting
    max_features=17,
    min_samples_split=5,  # Increasing min_samples_split for higher node purity
    min_samples_leaf=2,  # Increasing min_samples_leaf for higher node purity
    min_weight_fraction_leaf=0.0,  # Minimum weighted fraction of the total sum of weights for a leaf node
    max_leaf_nodes=17,  # Unlimited maximum leaf nodes
    bootstrap=True,  # Using bootstrap samples
    # n_jobs=-1,                        # Utilizing all processors for parallel processing (CPU)
    random_state=42,  # Setting a random seed for reproducibility
    warm_start=False,  # Not reusing previous solution (Useful when to analysis the performance of different value of estimator with same other parameters value)
    class_weight=None,  # No specific class weights
)

RF.fit(X_train,y_train)

"""### Evaluation"""

y_pred=RF.predict(X_test)
y_pred

print(classification_report(y_test,y_pred,target_names=['not deposit','deposit']))

"""### the Confusion matrix"""

cm_matrix = confusion_matrix(y_test,y_pred)
cm_display = ConfusionMatrixDisplay(confusion_matrix = cm_matrix, display_labels = ['Not Deposite','Deposite'])
cm_display.plot()
plt.title("Confusion Matrix of Random forest Classifier")
plt.show()

# Compute ROC curve and ROC area for each class
fpr, tpr, _ = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC)')
plt.legend(loc="lower right")
plt.show()

"""### save reults"""

model_result = ['Random Forest',accuracy_score(y_test,y_pred),
              precision_score(y_test,y_pred), recall_score(y_test,y_pred),
              f1_score(y_test,y_pred),roc_auc]
results.loc[len(results)]=model_result
results